% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/predict.R
\name{predict.regmdc}
\alias{predict.regmdc}
\title{Give predictions based on a nonparametric regression model with mixed derivative constraints}
\usage{
\method{predict}{regmdc}(regmdc_model, X_pred)
}
\arguments{
\item{regmdc_model}{An object of the class "regmdc". It is an object returned
by \code{\link{regmdc}}.}

\item{X_pred}{A numeric matrix of new data points. Each row corresponds to
an individual data point at which prediction will be made.}
}
\description{
Given the model built up from \code{\link{regmdc}}, this function provides
predictions at new data points.
}
\examples{
fstar <- function(x) {(
  (x[1] - 0.25 >= 0) + (x[2] - 0.25 >= 0)
  + (x[1] - 0.25 >= 0) * (x[2] - 0.25 >= 0)
)}  # the true underlying function
X_design <- expand.grid(rep(list(seq(0, 1, length.out = 10L)), 3L))
theta <- apply(X_design, MARGIN = 1L, FUN = fstar)
sigma <- 0.1
y <- theta + sigma * rnorm(nrow(X_design))

hk_model <- regmdc(X_design, y, s = 2L, method = "hk", V = 3.0)

X_pred <- c(1.0/3, 2.0/3, 1.0/3)
predict(hk_model, X_pred)
X_pred <- matrix(c(1.0/3, 2.0/3, 1.0/3,
                   2.0/3, 1.0/3, 2.0/3),
                 ncol = 3L, byrow = TRUE)
predict(hk_model, X_pred)

fstar <- function(x) {(
  - max(x[1] - 0.25, 0) - max(x[2] - 0.25, 0)
  - max(x[1] - 0.25, 0) * max(x[2] - 0.25, 0)
)}  # the true underlying function
X_design <- expand.grid(rep(list(seq(0, 1, length.out = 10L)), 3L))
theta <- apply(X_design, MARGIN = 1L, FUN = fstar)
sigma <- 0.1
y <- theta + sigma * rnorm(nrow(X_design))

mars_model <- regmdc(X_design, y, s = 2L, method = "mars", V = 3.0)

X_pred <- c(1.0/3, 2.0/3, 1.0/3)
predict(mars_model, X_pred)
X_pred <- matrix(c(1.0/3, 2.0/3, 1.0/3,
                   2.0/3, 1.0/3, 2.0/3),
                 ncol = 3L, byrow = TRUE)
predict(mars_model, X_pred)
}
\references{
Ki, D. and Guntuboyina, A. (2025+). Totally Concave Regression.
Available at \url{https://arxiv.org/abs/2501.04360}.

Ki, D., Fang, B., and Guntuboyina, A. (2024). MARS via LASSO.
\emph{Annals of Statistics}, \strong{52}(3), 1102-1126.

Fang, B., Guntuboyina, A., and Sen, B. (2021). Multivariate
extensions of isotonic regression and total variation denoising via entire
monotonicity and Hardyâ€”Krause variation. \emph{Annals of Statistics},
\strong{49}(2), 769-792.
}
\seealso{
\code{\link{regmdc}}, which produces nonparametric regression models
with mixed derivative constraints fit to data.
}
